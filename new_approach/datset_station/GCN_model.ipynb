{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzC8xc6FRNQg",
        "outputId": "aec73a7d-674f-481e-9e3e-1944801cf972"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XILSb5kvNrR2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your node embedding data\n",
        "nodes_df = pd.read_csv(\"/content/node embedding.csv\")\n",
        "\n",
        "\n",
        "nodes_df['label_binary'] = nodes_df['label'].apply(lambda x: 1 if x in [1, 2, 3, 4] else 0)\n",
        "\n",
        "\n",
        "nodes_df.to_csv(\"/content/node_embedding_binary_label.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import GCNConv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim // 2)\n",
        "        self.conv3 = GCNConv(hidden_dim // 2, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(hidden_dim // 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "def load_and_prepare_data(nodes_path, edges_path):\n",
        "    \"\"\"\n",
        "    Load and prepare data for GCN node classification with proper index mapping\n",
        "    \"\"\"\n",
        "    # Load nodes data\n",
        "    nodes_df = pd.read_csv(nodes_path)\n",
        "\n",
        "    # Create node ID mapping\n",
        "    unique_nodes = nodes_df['node_id'].unique()\n",
        "    node_id_to_idx = {node_id: idx for idx, node_id in enumerate(unique_nodes)}\n",
        "\n",
        "    # Separate features and labels\n",
        "    feature_columns =  nodes_df.columns.tolist()\n",
        "\n",
        "    # Create node features tensor\n",
        "    node_features = nodes_df[feature_columns].values\n",
        "    x = torch.FloatTensor(node_features)\n",
        "\n",
        "    # Get labels (assuming you have a 'label' column)\n",
        "    labels = nodes_df['label_binary'].values\n",
        "    y = torch.LongTensor(labels)\n",
        "\n",
        "    # Load edges data\n",
        "    edges_df = pd.read_csv(edges_path)\n",
        "\n",
        "    # Map node IDs to indices\n",
        "    edge_index_source = [node_id_to_idx[node_id] for node_id in edges_df['node1']]\n",
        "    edge_index_target = [node_id_to_idx[node_id] for node_id in edges_df['node2']]\n",
        "\n",
        "    # Create edge index tensor\n",
        "    edge_index = torch.tensor([edge_index_source, edge_index_target], dtype=torch.long)\n",
        "\n",
        "    # Create PyG Data object\n",
        "    data = Data(x=x,\n",
        "                edge_index=edge_index,\n",
        "                y=y,\n",
        "                node_id_to_idx=node_id_to_idx)\n",
        "\n",
        "    print(f\"Number of nodes: {x.shape[0]}\")\n",
        "    print(f\"Number of edges: {edge_index.shape[1]}\")\n",
        "    print(f\"Number of node features: {x.shape[1]}\")\n",
        "    print(f\"Number of classes: {len(torch.unique(y))}\")\n",
        "    print(f\"Edge index range: [{edge_index.min()}, {edge_index.max()}]\")\n",
        "\n",
        "    return data\n",
        "\n",
        "def create_train_val_test_masks(data, train_size=0.5, val_size=0.45):\n",
        "    \"\"\"Create masks for train/validation/test split\"\"\"\n",
        "    num_nodes = data.x.size(0)\n",
        "    indices = np.arange(num_nodes)\n",
        "\n",
        "    # Split indices into train, validation, and test\n",
        "    train_idx, temp_idx = train_test_split(indices, train_size=train_size, random_state=42)\n",
        "    val_idx, test_idx = train_test_split(temp_idx, train_size=val_size/(1-train_size), random_state=42)\n",
        "\n",
        "    # Create boolean masks\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[train_idx] = True\n",
        "    val_mask[val_idx] = True\n",
        "    test_mask[test_idx] = True\n",
        "\n",
        "    data.train_mask = train_mask\n",
        "    data.val_mask = val_mask\n",
        "    data.test_mask = test_mask\n",
        "\n",
        "    return data\n",
        "\n",
        "def train_model(model, data, epochs=2, lr=0.00001):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            out = model(data)\n",
        "            val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "\n",
        "            # Get predictions\n",
        "            pred = out.argmax(dim=1)\n",
        "            train_acc = accuracy_score(data.y[data.train_mask].numpy(),\n",
        "                                     pred[data.train_mask].numpy())\n",
        "            val_acc = accuracy_score(data.y[data.val_mask].numpy(),\n",
        "                                   pred[data.val_mask].numpy())\n",
        "\n",
        "        if epoch % 20 == 0:\n",
        "            print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
        "                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, data):\n",
        "    \"\"\"Evaluate the model on test set\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "\n",
        "        # Get test accuracy\n",
        "        test_acc = accuracy_score(data.y[data.test_mask].numpy(),\n",
        "                                pred[data.test_mask].numpy())\n",
        "\n",
        "        # Get detailed classification report\n",
        "        report = classification_report(data.y[data.test_mask].numpy(),\n",
        "                                    pred[data.test_mask].numpy())\n",
        "\n",
        "    return test_acc, report, pred\n",
        "\n",
        "def main(nodes_path, edges_path):\n",
        "    # Load and prepare data\n",
        "    data = load_and_prepare_data(nodes_path, edges_path)\n",
        "\n",
        "    # Create train/val/test splits\n",
        "    data = create_train_val_test_masks(data)\n",
        "\n",
        "    # Initialize model\n",
        "    input_dim = data.x.size(1)  # Number of node features\n",
        "    hidden_dim = 256*16            # Adjustable hidden dimension\n",
        "    num_classes = len(torch.unique(data.y))  # Number of unique classes\n",
        "\n",
        "    model = GCN(input_dim=input_dim,\n",
        "                hidden_dim=hidden_dim,\n",
        "                num_classes=num_classes)\n",
        "\n",
        "    # Train model\n",
        "    model = train_model(model, data)\n",
        "\n",
        "    # Evaluate model\n",
        "    test_acc, classification_rep, predictions = evaluate_model(model, data)\n",
        "\n",
        "    print(\"\\nTest Accuracy:\", test_acc)\n",
        "    # print(\"\\nClassification Report:\")\n",
        "    # print(classification_rep)\n",
        "\n",
        "    # Save predictions\n",
        "    all_predictions = pd.DataFrame({\n",
        "        'node_id': list(data.node_id_to_idx.keys()),\n",
        "        'predicted_class': predictions.numpy()\n",
        "    })\n",
        "    all_predictions.to_csv('predictions.csv', index=False)\n",
        "\n",
        "    return model, data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    nodes_path = \"/content/node_embedding_binary_label.csv\"\n",
        "    edges_path = \"/content/edge embedding.csv\"\n",
        "\n",
        "    model, data = main(nodes_path, edges_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR5pEeLOOQOk",
        "outputId": "dbd89e2e-c4d3-43f1-ed21-b079df770379"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 150\n",
            "Number of edges: 281\n",
            "Number of node features: 58\n",
            "Number of classes: 2\n",
            "Edge index range: [0, 149]\n",
            "Epoch 000, Loss: 1.2054, Train Acc: 0.3333, Val Loss: 4.0742, Val Acc: 0.3134\n",
            "\n",
            "Test Accuracy: 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MjWInA33RHdg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}